#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¿ç§»ä¿®å¤éªŒè¯æµ‹è¯•è„šæœ¬

æµ‹è¯•å†…å®¹:
1. to_cuda() å‡½æ•°çš„è®¾å¤‡ç®¡ç†ä¿®å¤ (é—®é¢˜6)
2. transformer.py ä¸­ .new() æ–¹æ³•çš„ä¿®å¤ (é—®é¢˜7)
3. ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¿®å¤ (é—®é¢˜5)
"""

import sys
import paddle
from symbolicregression.utils import to_cuda
from paddle_utils import device2int


def test_device_management():
    """æµ‹è¯•é—®é¢˜6: tensor.cuda(device=) å‚æ•°ä¿®å¤"""
    print("=" * 60)
    print("æµ‹è¯• 1: to_cuda å‡½æ•° (é—®é¢˜6ä¿®å¤)")
    print("=" * 60)

    try:
        # æµ‹è¯•åŸºæœ¬å¼ é‡ç§»åŠ¨
        x = paddle.randn([3, 4])
        print(f"âœ“ åˆ›å»ºå¼ é‡æˆåŠŸï¼ŒåŸå§‹è®¾å¤‡: {x.place}")

        # æµ‹è¯• to_cuda å‡½æ•°
        y, = to_cuda(x, device=0)
        print(f"âœ“ to_cuda(device=0) æˆåŠŸï¼Œç›®æ ‡è®¾å¤‡: {y.place}")

        # æµ‹è¯•å­—ç¬¦ä¸²è®¾å¤‡å‚æ•°
        a = paddle.randn([2, 3])
        b, = to_cuda(a, device="cuda:0")
        print(f"âœ“ to_cuda(device='cuda:0') æˆåŠŸï¼Œç›®æ ‡è®¾å¤‡: {b.place}")

        # æµ‹è¯• None å€¼å¤„ç†
        x1 = paddle.randn([2, 2])
        x2 = None
        x3 = paddle.randn([3, 3])
        result = to_cuda(x1, x2, x3, device=0)
        assert result[1] is None, "Noneå€¼åº”è¯¥ä¿æŒä¸ºNone"
        print(f"âœ“ None å€¼å¤„ç†æ­£ç¡®")

        # æµ‹è¯• use_cpu æ ‡å¿—
        x = paddle.randn([2, 2])
        y, = to_cuda(x, use_cpu=True, device=0)
        print(f"âœ“ use_cpu=True æ¨¡å¼æ­£å¸¸")

        print("\nâœ… é—®é¢˜6ä¿®å¤éªŒè¯é€šè¿‡: to_cuda å‡½æ•°å·¥ä½œæ­£å¸¸\n")
        return True

    except Exception as e:
        print(f"\nâŒ é—®é¢˜6ä¿®å¤éªŒè¯å¤±è´¥:")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_transformer_tensor_creation():
    """æµ‹è¯•é—®é¢˜7: tensor.new() æ–¹æ³•ä¿®å¤"""
    print("=" * 60)
    print("æµ‹è¯• 2: Transformer å¼ é‡åˆ›å»º (é—®é¢˜7ä¿®å¤)")
    print("=" * 60)

    try:
        # å¯¼å…¥ transformer æ¨¡å—
        from symbolicregression.model.transformer import TransformerModel
        from symbolicregression import envs
        import argparse

        # åˆ›å»ºæœ€å°åŒ–å‚æ•°
        params = argparse.Namespace(
            # ç¯å¢ƒåŸºæœ¬å‚æ•°ï¼ˆå¿…éœ€ï¼‰
            env_name='char_sp',
            env_base_seed=-1,
            # ç¼–ç å™¨å‚æ•°
            enc_emb_dim=128,
            n_enc_layers=1,
            n_enc_heads=4,
            n_enc_hidden_layers=1,
            enc_attention_dropout=0.1,
            dropout=0.1,
            attention_dropout=0.1,
            # è§£ç å™¨å‚æ•°
            dec_emb_dim=128,
            n_dec_layers=1,
            n_dec_heads=4,
            n_dec_hidden_layers=1,
            dec_attention_dropout=0.1,
            # å…¶ä»–
            sinusoidal_embeddings=False,
            share_inout_emb=False,
            reload_emb='',
            emb_dim=128,
            # ç¯å¢ƒå‚æ•°
            operators='add:10,mul:10,sub:5,div:5',
            max_ops=5,
            int_base=10,
            balanced_ops=True,
            positive=True,
            nonnegative=True,
            max_len=50,
            precision=3,
            double_seq=True,
            # æ•°æ®ç”Ÿæˆ
            n_points=10,
            n_output=1,
            n_output_units=1,
            use_hints='units,complexity',
            max_hint_complexity=5,
            # è¯è¡¨å‚æ•°
            max_int=100,
            # é¢å¤–å¿…éœ€å‚æ•°
            max_number_bags=None,
            skip_zero_gradient=True,
            use_controller=False
        )

        print("âœ“ å‚æ•°åˆå§‹åŒ–æˆåŠŸ")

        # åˆ›å»ºç¯å¢ƒ
        env = envs.build_env(params)
        print("âœ“ ç¯å¢ƒåˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºç®€å•çš„ id2word è¯è¡¨
        id2word = {i: str(i) for i in range(100)}
        id2word[0] = '<PAD>'
        id2word[1] = '<EOS>'
        id2word[2] = '<BOS>'

        # æµ‹è¯•ç¼–ç å™¨åˆå§‹åŒ–ï¼ˆä¸ä¼šè§¦å‘ .new() è°ƒç”¨ï¼‰
        encoder = TransformerModel(
            params=params,
            id2word=id2word,
            is_encoder=True,
            is_decoder=False,
            with_output=False
        )
        print("âœ“ Transformerç¼–ç å™¨åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯•è§£ç å™¨åˆå§‹åŒ–
        decoder = TransformerModel(
            params=params,
            id2word=id2word,
            is_encoder=False,
            is_decoder=True,
            with_output=True
        )
        print("âœ“ Transformerè§£ç å™¨åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆä¼šè§¦å‘å†…éƒ¨å¼ é‡åˆ›å»ºï¼‰
        batch_size = 2
        seq_len = 10

        # åˆ›å»ºè¾“å…¥å¼ é‡
        x = paddle.randn([seq_len, batch_size, params.enc_emb_dim])
        lengths = paddle.to_tensor([seq_len, seq_len], dtype='int64')

        # ç¼–ç å™¨å‰å‘
        encoded = encoder.fwd(
            mode='fwd',
            x=x,
            lengths=lengths,
            causal=False
        )
        print(f"âœ“ ç¼–ç å™¨å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {encoded.shape}")

        # è§£ç å™¨å‰å‘ï¼ˆéœ€è¦ç›®æ ‡åºåˆ—ï¼‰
        y = paddle.randint(0, 100, [seq_len, batch_size], dtype='int64')
        decoded = decoder.fwd(
            mode='fwd',
            x=y,
            lengths=lengths,
            causal=True,
            src_enc=encoded,
            src_len=lengths
        )
        print(f"âœ“ è§£ç å™¨å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {decoded.shape}")

        print("\nâœ… é—®é¢˜7ä¿®å¤éªŒè¯é€šè¿‡: Transformerå¼ é‡åˆ›å»ºæ­£å¸¸\n")
        return True

    except Exception as e:
        print(f"\nâŒ é—®é¢˜7ä¿®å¤éªŒè¯å¤±è´¥:")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_optimizer_initialization():
    """æµ‹è¯•é—®é¢˜5: ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¿®å¤"""
    print("=" * 60)
    print("æµ‹è¯• 3: ä¼˜åŒ–å™¨åˆå§‹åŒ– (é—®é¢˜5ä¿®å¤)")
    print("=" * 60)

    try:
        from symbolicregression.optim import (
            Adam,
            AdamWithWarmup,
            AdamInverseSqrtWithWarmup,
            AdamCosineWithWarmup
        )

        # åˆ›å»ºç®€å•æ¨¡å‹
        model = paddle.nn.Linear(10, 5)
        params = list(model.parameters())

        # æµ‹è¯• Adam
        optimizer1 = Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01)
        print(f"âœ“ Adam åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯• AdamWithWarmup
        optimizer2 = AdamWithWarmup(
            params,
            lr=0.001,
            warmup_updates=100,
            warmup_init_lr=1e-7
        )
        print(f"âœ“ AdamWithWarmup åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯• AdamInverseSqrtWithWarmup
        optimizer3 = AdamInverseSqrtWithWarmup(
            params,
            lr=0.001,
            warmup_updates=100,
            warmup_init_lr=1e-7,
            exp_factor=0.5
        )
        print(f"âœ“ AdamInverseSqrtWithWarmup åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯• AdamCosineWithWarmup
        optimizer4 = AdamCosineWithWarmup(
            params,
            lr=0.001,
            warmup_updates=100,
            warmup_init_lr=1e-7,
            min_lr=1e-9,
            init_period=1000,
            period_mult=1,
            lr_shrink=0.75
        )
        print(f"âœ“ AdamCosineWithWarmup åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯•ä¼˜åŒ–æ­¥éª¤
        x = paddle.randn([4, 10])
        y = model(x)
        loss = y.sum()
        loss.backward()

        optimizer1.step()
        optimizer1.clear_grad()
        print(f"âœ“ ä¼˜åŒ–å™¨stepæ‰§è¡ŒæˆåŠŸ")

        print("\nâœ… é—®é¢˜5ä¿®å¤éªŒè¯é€šè¿‡: æ‰€æœ‰ä¼˜åŒ–å™¨åˆå§‹åŒ–æ­£å¸¸\n")
        return True

    except Exception as e:
        print(f"\nâŒ é—®é¢˜5ä¿®å¤éªŒè¯å¤±è´¥:")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n")
    print("ğŸ”§" * 30)
    print("å¼€å§‹éªŒè¯PaddlePaddleè¿ç§»ä¿®å¤...")
    print("ğŸ”§" * 30)
    print("\n")

    results = []

    # æµ‹è¯•1: è®¾å¤‡ç®¡ç†
    results.append(("to_cudaå‡½æ•° (é—®é¢˜6)", test_device_management()))

    # æµ‹è¯•2: Transformerå¼ é‡åˆ›å»º
    results.append(("Transformerå¼ é‡åˆ›å»º (é—®é¢˜7)", test_transformer_tensor_creation()))

    # æµ‹è¯•3: ä¼˜åŒ–å™¨åˆå§‹åŒ–
    results.append(("ä¼˜åŒ–å™¨åˆå§‹åŒ– (é—®é¢˜5)", test_optimizer_initialization()))

    # æ‰“å°æ€»ç»“
    print("=" * 60)
    print("æµ‹è¯•æ€»ç»“:")
    print("=" * 60)

    all_passed = True
    for name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"  {name}: {status}")
        all_passed = all_passed and passed

    print("=" * 60)

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! PaddlePaddleè¿ç§»ä¿®å¤æˆåŠŸ!")
        print("\nä¿®å¤æ€»ç»“:")
        print("  é—®é¢˜5: âœ… ä¼˜åŒ–å™¨åŸºç±»åˆå§‹åŒ–ç­¾åå·²ä¿®å¤ (optim.py)")
        print("  é—®é¢˜6: âœ… tensor.cuda(device=) å‚æ•°å·²ä¿®å¤ (utils.py)")
        print("  é—®é¢˜7: âœ… tensor.new() æ–¹æ³•å·²æ›¿æ¢ (transformer.py, 15å¤„)")
        print("\næ‰€æœ‰ä¿®å¤å·²è®°å½•åˆ°: PADDLE_MIGRATION.md")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œå®Œæ•´è®­ç»ƒ: bash ./bash/train_small.sh")
        print("  2. éªŒè¯è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›æ€§")
        print("  3. å¯¹æ¯”PyTorchç‰ˆæœ¬çš„æ•°å€¼ç²¾åº¦")
        return 0
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥,è¯·æ£€æŸ¥ä¿®å¤!")
        return 1


if __name__ == "__main__":
    sys.exit(main())
