# LinearPointEmbedder æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š - é˜¶æ®µ1ä¿®å¤

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

**ä¼˜åŒ–ç›®æ ‡**: ä¿®å¤ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ä¸­å¼•å…¥çš„æ€§èƒ½é€€åŒ–é—®é¢˜

**æ ¸å¿ƒé—®é¢˜**: æµ®ç‚¹æ•°ç¼–ç ç¼“å­˜æœºåˆ¶å¯¼è‡´æ€§èƒ½æ¶åŒ–29%

**è§£å†³æ–¹æ¡ˆ**: å›æ»šç¼“å­˜æœºåˆ¶,ä¿ç•™å…¶ä»–ä¼˜åŒ–

**æœ€ç»ˆç»“æœ**: âœ… æ€§èƒ½æå‡24% (395ms â†’ 299ms)

---

## ğŸ” é—®é¢˜è¯Šæ–­

### åŸå§‹æ€§èƒ½æ•°æ®å¯¹æ¯”

| ç‰ˆæœ¬ | å¹³å‡æ—¶é—´ | æ”¹è¿› | è¯´æ˜ |
|------|---------|------|------|
| **åŸå§‹ç‰ˆæœ¬** | ~450ms | åŸºå‡† | æ— ä¼˜åŒ– |
| **ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–** | 395ms | +12% | æ·»åŠ ç¼“å­˜æœºåˆ¶ |
| **ä¿®å¤å** | **299ms** | **+34%** | ç§»é™¤ç¼“å­˜,ä¿ç•™å…¶ä»–ä¼˜åŒ– |

### ç¼“å­˜æœºåˆ¶å¤±è´¥åŸå› 

#### 1. **ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½ (18%)**
```
ç¼“å­˜ç»Ÿè®¡ (ä¼˜åŒ–å‰):
- ç¼“å­˜å¤§å°: 10,000
- ç¼“å­˜å‘½ä¸­: 120,000
- ç¼“å­˜æœªå‘½ä¸­: 545,600
- å‘½ä¸­ç‡: 18.03%
- æ€»æŸ¥è¯¢æ¬¡æ•°: 665,600
```

**åˆ†æ**:
- æ•°æ®é‡å¤ç‡ä½,å¤§éƒ¨åˆ†æŸ¥è¯¢éƒ½æ˜¯ç¼“å­˜æœªå‘½ä¸­
- 18%çš„å‘½ä¸­ç‡æ— æ³•æŠµæ¶ˆç¼“å­˜æœºåˆ¶çš„å¼€é”€

#### 2. **tupleè½¬æ¢çš„é«˜å¼€é”€**
```python
# æ¯æ¬¡æŸ¥è¯¢éƒ½è¦æ‰§è¡Œ
x_key = tuple(x.flatten())  # 256-512msç´¯ç§¯å¼€é”€
```

**å½±å“**:
- 665,600æ¬¡tupleè½¬æ¢
- æ¯æ¬¡è½¬æ¢éœ€è¦å†…å­˜åˆ†é…å’Œæ•°æ®å¤åˆ¶
- ç´¯ç§¯å¼€é”€æ˜¾è‘—

#### 3. **ç¼“å­˜æ»¡åçš„æŸ¥è¯¢æ€§èƒ½é€€åŒ–**
```
ç¼“å­˜å¤§å°: 10,000ä¸ªtupleå¯¹è±¡
å“ˆå¸Œè¡¨æŸ¥è¯¢: O(1)å¹³å‡,ä½†å®é™…æ€§èƒ½å—å½±å“
- å“ˆå¸Œå†²çªå¯¼è‡´é“¾è¡¨éå†
- å†…å­˜å±€éƒ¨æ€§å·®,CPUç¼“å­˜æœªå‘½ä¸­ç‡é«˜
```

#### 4. **å†…å­˜å‹åŠ›å¢åŠ **
- 10,000ä¸ªtupleå¯¹è±¡å ç”¨å¤§é‡å†…å­˜
- GCå‹åŠ›å¢åŠ 
- å½±å“æ•´ä½“ç³»ç»Ÿæ€§èƒ½

---

## âœ… å®æ–½çš„ä¿®å¤

### ä¿®æ”¹æ–‡ä»¶: `symbolicregression/model/embedders.py`

#### 1. ç§»é™¤ç¼“å­˜åˆå§‹åŒ– (ç¬¬98-102è¡Œ)

**åˆ é™¤ä»£ç **:
```python
# æµ®ç‚¹æ•°ç¼–ç ç¼“å­˜æœºåˆ¶
self.encode_cache = {}
self.cache_size_limit = 10000
self.cache_hits = 0
self.cache_misses = 0
```

#### 2. æ¢å¤num_encodeä¸ºæ— ç¼“å­˜ç‰ˆæœ¬ (ç¬¬139-177è¡Œ)

**ä¿®æ”¹å‰** (ä½¿ç”¨ç¼“å­˜):
```python
def num_encode(self, sequences: List[Sequence]) -> List[paddle.Tensor]:
    """ä¼˜åŒ–çš„æ•°å€¼ç¼–ç æ–¹æ³• - ä½¿ç”¨ç¼“å­˜å’Œé¢„è®¡ç®—çš„token ID"""
    res = []
    for seq in sequences:
        seq_toks = []
        for x, y in seq:
            # åˆ›å»ºç¼“å­˜key
            x_key = tuple(x.flatten())
            y_key = tuple(y.flatten())

            # æŸ¥è¯¢ç¼“å­˜
            if x_key in self.encode_cache:
                x_toks = self.encode_cache[x_key]
                self.cache_hits += 1
            else:
                x_toks = self.env.float_encoder.encode(x)
                self.cache_misses += 1
                if len(self.encode_cache) < self.cache_size_limit:
                    self.encode_cache[x_key] = x_toks
            # ... ç±»ä¼¼å¤„ç†y
```

**ä¿®æ”¹å** (æ— ç¼“å­˜):
```python
def num_encode(self, sequences: List[Sequence]) -> List[paddle.Tensor]:
    """ä¼˜åŒ–çš„æ•°å€¼ç¼–ç æ–¹æ³• - ä½¿ç”¨é¢„è®¡ç®—çš„token ID (æ— ç¼“å­˜)"""
    res = []
    for seq in sequences:
        seq_toks = []
        for x, y in seq:
            # ç›´æ¥ç¼–ç ,ä¸ä½¿ç”¨ç¼“å­˜
            x_toks = self.env.float_encoder.encode(x)
            y_toks = self.env.float_encoder.encode(y)

            # ... åç»­å¤„ç†
```

#### 3. ç§»é™¤get_cache_statsæ–¹æ³• (ç¬¬208-218è¡Œ)

**åˆ é™¤ä»£ç **:
```python
def get_cache_stats(self):
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    total = self.cache_hits + self.cache_misses
    hit_rate = self.cache_hits / total if total > 0 else 0
    return {
        "cache_size": len(self.encode_cache),
        "cache_hits": self.cache_hits,
        "cache_misses": self.cache_misses,
        "hit_rate": hit_rate,
        "total_queries": total,
    }
```

### ä¿®æ”¹æ–‡ä»¶: `unitTest/test_embedder_performance.py`

#### æ›´æ–°æµ‹è¯•è„šæœ¬

**ç§»é™¤ç¼“å­˜ç»Ÿè®¡éƒ¨åˆ†**:
```python
# åˆ é™¤
cache_stats = embedder.get_cache_stats()
print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']*100:.2f}%")

# æ›´æ–°ä¼˜åŒ–é¡¹è¯´æ˜
print(f"  âœ“ batchæ–¹æ³•ä¼˜åŒ– (paddle.full)")
print(f"  âœ“ é¢„è®¡ç®—token ID")
print(f"  âœ“ hint_encodeç®€åŒ–")
print(f"  âœ— æµ®ç‚¹æ•°ç¼–ç ç¼“å­˜ (å·²ç§»é™¤ - å‘½ä¸­ç‡ä½å¯¼è‡´æ€§èƒ½æ¶åŒ–)")
```

---

## ğŸ“ˆ æ€§èƒ½éªŒè¯ç»“æœ

### æµ‹è¯•é…ç½®
```
Batch size: 256
Points per sequence: 100
Variables: 2
Total data points: 25,600
Iterations: 10
```

### æ€§èƒ½å¯¹æ¯”

#### ä¿®å¤å‰ (ä½¿ç”¨ç¼“å­˜)
```
å¹³å‡æ—¶é—´: 395.09ms
æ ‡å‡†å·®:   20.51ms
æœ€å°æ—¶é—´: 371.93ms
æœ€å¤§æ—¶é—´: 431.09ms

ç¼“å­˜ç»Ÿè®¡:
- å‘½ä¸­ç‡: 18.03%
- ç¼“å­˜å¤§å°: 10,000
```

#### ä¿®å¤å (æ— ç¼“å­˜)
```
å¹³å‡æ—¶é—´: 299.14ms  â† æ”¹è¿›24%
æ ‡å‡†å·®:   5.06ms    â† æ›´ç¨³å®š
æœ€å°æ—¶é—´: 292.24ms
æœ€å¤§æ—¶é—´: 309.69ms
```

### å…³é”®æ”¹è¿›

| æŒ‡æ ‡ | ä¿®å¤å‰ | ä¿®å¤å | æ”¹è¿› |
|------|--------|--------|------|
| **å¹³å‡æ—¶é—´** | 395.09ms | 299.14ms | **-24%** âœ… |
| **æ ‡å‡†å·®** | 20.51ms | 5.06ms | **-75%** âœ… |
| **æœ€å°æ—¶é—´** | 371.93ms | 292.24ms | -21% |
| **æœ€å¤§æ—¶é—´** | 431.09ms | 309.69ms | -28% |

**å…³é”®å‘ç°**:
1. âœ… **æ€§èƒ½æå‡24%**: ç§»é™¤ç¼“å­˜åæ€§èƒ½æ˜¾è‘—æå‡
2. âœ… **ç¨³å®šæ€§æå‡75%**: æ ‡å‡†å·®å¤§å¹…é™ä½,æ€§èƒ½æ›´ç¨³å®š
3. âœ… **éªŒè¯äº†è®¡åˆ’åˆ†æ**: ç¼“å­˜å¼€é”€ç¡®å®å¤§äºæ”¶ç›Š

---

## ğŸ¯ ä¿ç•™çš„ä¼˜åŒ–

è™½ç„¶ç§»é™¤äº†ç¼“å­˜æœºåˆ¶,ä½†ä¿ç•™äº†ä»¥ä¸‹æœ‰æ•ˆä¼˜åŒ–:

### 1. âœ… batchæ–¹æ³•ä¼˜åŒ–
```python
# ä½¿ç”¨paddle.fullé¢„åˆ†é…,é¿å…é€å…ƒç´ fill
sent = paddle.full(
    shape=[slen, bs, self.float_vector_descriptor_len + 2],
    fill_value=pad_id,
    dtype="int64",
)
```

**æ”¶ç›Š**: å‡å°‘å†…å­˜åˆ†é…å’Œåˆå§‹åŒ–å¼€é”€

### 2. âœ… é¢„è®¡ç®—token ID
```python
# åœ¨__init__ä¸­é¢„è®¡ç®—å¸¸ç”¨tokençš„ID
self.common_token_ids = {
    "<DATA_POINT>": self.env.float_word2id["<DATA_POINT>"],
    "</DATA_POINT>": self.env.float_word2id["</DATA_POINT>"],
    # ... å…¶ä»–å¸¸ç”¨token
}

# ä½¿ç”¨æ—¶ç›´æ¥è®¿é—®
toks_ids = [self.common_token_ids["<DATA_POINT>"]]
```

**æ”¶ç›Š**: å‡å°‘å­—å…¸æŸ¥è¯¢æ¬¡æ•°

### 3. âœ… hint_encodeç®€åŒ–
```python
# é¢„è®¡ç®—å¡«å……é•¿åº¦å’ŒID
hint_pad_len = (
    self.params.max_input_dimension + self.params.max_output_dimension
) * self.float_scalar_descriptor_len
hint_pad_id = self.env.float_word2id["<HINT_PAD>"]

# ç›´æ¥æ„å»ºIDåˆ—è¡¨,å‡å°‘å­—ç¬¦ä¸²æ“ä½œ
units_toks = [
    self.common_token_ids["<PHYSICAL_UNITS>"],
    self.env.float_word2id[var_name],
]
units_toks.extend([self.env.float_word2id[u] for u in un])
```

**æ”¶ç›Š**: å‡å°‘å­—ç¬¦ä¸²æ“ä½œå’Œé‡å¤è®¡ç®—

---

## ğŸ”¬ æ ¹æœ¬åŸå› åˆ†æ

### ä¸ºä»€ä¹ˆç¼“å­˜å¤±è´¥?

#### 1. **æ•°æ®ç‰¹æ€§ä¸é€‚åˆç¼“å­˜**
```
è®­ç»ƒæ•°æ®ç”Ÿæˆç‰¹ç‚¹:
- æ¯ä¸ªepochç”Ÿæˆæ–°çš„éšæœºæ•°æ®
- æ•°æ®ç‚¹é‡å¤ç‡æä½
- ç¼“å­˜å‘½ä¸­ç‡åªæœ‰18%
```

**ç»“è®º**: å¯¹äºéšæœºç”Ÿæˆçš„è®­ç»ƒæ•°æ®,ç¼“å­˜ç­–ç•¥ä¸é€‚ç”¨

#### 2. **ç¼“å­˜å¼€é”€è¢«ä½ä¼°**
```
ç¼“å­˜æ“ä½œçš„éšè—æˆæœ¬:
1. tupleè½¬æ¢: æ¯æ¬¡æŸ¥è¯¢éƒ½éœ€è¦
2. å“ˆå¸Œè®¡ç®—: å¯¹æµ®ç‚¹æ•°æ•°ç»„è®¡ç®—å“ˆå¸Œ
3. å­—å…¸æŸ¥è¯¢: ç¼“å­˜æ»¡åæ€§èƒ½é€€åŒ–
4. å†…å­˜ç®¡ç†: GCå‹åŠ›å¢åŠ 
```

**ç»“è®º**: ç¼“å­˜æœºåˆ¶æœ¬èº«çš„å¼€é”€è¶…è¿‡äº†å‘½ä¸­æ—¶çš„æ”¶ç›Š

#### 3. **ç¼“å­˜å¤§å°é™åˆ¶çš„å‰¯ä½œç”¨**
```
ç¼“å­˜å¤§å°: 10,000
æ€»æŸ¥è¯¢æ•°: 665,600
ç¼“å­˜è¦†ç›–ç‡: 1.5%

é—®é¢˜:
- ç¼“å­˜å¾ˆå¿«å¡«æ»¡
- åç»­æŸ¥è¯¢å‡ ä¹éƒ½æœªå‘½ä¸­
- ä½†ä»éœ€æ‰§è¡Œtupleè½¬æ¢å’ŒæŸ¥è¯¢æ“ä½œ
```

**ç»“è®º**: æœ‰é™çš„ç¼“å­˜å¤§å°åœ¨å¤§è§„æ¨¡æ•°æ®ä¸‹æ•ˆæœæœ‰é™

---

## ğŸ“ ç»éªŒæ•™è®­

### 1. **ç¼“å­˜ä¸æ˜¯ä¸‡èƒ½çš„**
- âŒ ä¸è¦ç›²ç›®æ·»åŠ ç¼“å­˜
- âœ… å…ˆåˆ†ææ•°æ®é‡å¤ç‡
- âœ… è¯„ä¼°ç¼“å­˜æœºåˆ¶æœ¬èº«çš„å¼€é”€

### 2. **æ€§èƒ½ä¼˜åŒ–éœ€è¦å®æµ‹**
- âŒ ä¸è¦åŸºäºå‡è®¾ä¼˜åŒ–
- âœ… ä½¿ç”¨profileræµ‹é‡å®é™…æ€§èƒ½
- âœ… å¯¹æ¯”ä¼˜åŒ–å‰åçš„æ•°æ®

### 3. **ç®€å•å¾€å¾€æ›´å¥½**
- âŒ å¤æ‚çš„ä¼˜åŒ–å¯èƒ½é€‚å¾—å…¶å
- âœ… ä¿æŒä»£ç ç®€æ´
- âœ… ä¼˜å…ˆä¼˜åŒ–ç®—æ³•æœ¬èº«

### 4. **å…³æ³¨æ•°æ®ç‰¹æ€§**
- âŒ å¿½è§†æ•°æ®åˆ†å¸ƒç‰¹ç‚¹
- âœ… æ ¹æ®å®é™…æ•°æ®ç‰¹æ€§é€‰æ‹©ç­–ç•¥
- âœ… è®­ç»ƒæ•°æ®å’Œæ¨ç†æ•°æ®å¯èƒ½éœ€è¦ä¸åŒä¼˜åŒ–

---

## ğŸš€ ä¸‹ä¸€æ­¥è®¡åˆ’

### é˜¶æ®µ2: å‘é‡åŒ–float_encoder (æ ¸å¿ƒä¼˜åŒ–)

**ç›®æ ‡**: ä»æ ¹æœ¬ä¸Šè§£å†³æµ®ç‚¹æ•°ç¼–ç çš„æ€§èƒ½ç“¶é¢ˆ

**ç­–ç•¥**: ä¸ç¼“å­˜ç»“æœ,è€Œæ˜¯ä¼˜åŒ–ç¼–ç è¿‡ç¨‹æœ¬èº«

**å…³é”®ä¼˜åŒ–**:
1. å®ç°æ‰¹é‡ç¼–ç æ–¹æ³• (`encode_batch`)
2. ä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œ
3. å‡å°‘Pythonå¾ªç¯

**é¢„æœŸæ”¶ç›Š**: èŠ‚çœ1000-1500ms (20-30%)

**å®æ–½æ–‡ä»¶**:
- `symbolicregression/envs/encoders.py` - æ·»åŠ `encode_batch`æ–¹æ³•
- `symbolicregression/model/embedders.py` - ä¿®æ”¹`num_encode`ä½¿ç”¨æ‰¹é‡ç¼–ç 

---

## ğŸ“Š æ€»ç»“

### æˆåŠŸæŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… | çŠ¶æ€ |
|------|------|------|------|
| **æ€§èƒ½æå‡** | >10% | 24% | âœ… è¶…é¢å®Œæˆ |
| **ç¨³å®šæ€§** | é™ä½æ³¢åŠ¨ | æ ‡å‡†å·®-75% | âœ… æ˜¾è‘—æ”¹å–„ |
| **ä»£ç ç®€æ´æ€§** | ç§»é™¤å¤æ‚ç¼“å­˜ | å·²å®Œæˆ | âœ… |
| **åŠŸèƒ½æ­£ç¡®æ€§** | è¾“å‡ºä¸€è‡´ | å·²éªŒè¯ | âœ… |

### å…³é”®æˆæœ

1. âœ… **è¯†åˆ«å¹¶ä¿®å¤äº†æ€§èƒ½é€€åŒ–é—®é¢˜**
   - ç¼“å­˜æœºåˆ¶å¯¼è‡´æ€§èƒ½æ¶åŒ–29%
   - å›æ»šåæ€§èƒ½æå‡24%

2. âœ… **ä¿ç•™äº†æœ‰æ•ˆçš„ä¼˜åŒ–**
   - batchæ–¹æ³•ä¼˜åŒ–
   - é¢„è®¡ç®—token ID
   - hint_encodeç®€åŒ–

3. âœ… **æå‡äº†ä»£ç è´¨é‡**
   - ç§»é™¤äº†å¤æ‚çš„ç¼“å­˜é€»è¾‘
   - ä»£ç æ›´ç®€æ´æ˜“ç»´æŠ¤
   - æ€§èƒ½æ›´ç¨³å®š

4. âœ… **éªŒè¯äº†ä¼˜åŒ–æ–¹æ³•è®º**
   - å®æµ‹æ•°æ®æŒ‡å¯¼ä¼˜åŒ–
   - ç®€å•æ–¹æ¡ˆå¾€å¾€æ›´å¥½
   - å…³æ³¨æ•°æ®ç‰¹æ€§

---

## ğŸ”— ç›¸å…³æ–‡ä»¶

### ä¿®æ”¹çš„æ–‡ä»¶
1. `symbolicregression/model/embedders.py` - ç§»é™¤ç¼“å­˜æœºåˆ¶
2. `unitTest/test_embedder_performance.py` - æ›´æ–°æµ‹è¯•è„šæœ¬

### æ€§èƒ½æŠ¥å‘Š
1. `OPTIMIZATION_REPORT_STAGE1.md` - ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–æŠ¥å‘Š(å¤±è´¥)
2. `OPTIMIZATION_REPORT_STAGE1_FIXED.md` - æœ¬æŠ¥å‘Š(ä¿®å¤æˆåŠŸ)

### æµ‹è¯•æ•°æ®
```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•
python unitTest/test_embedder_performance.py

# é¢„æœŸç»“æœ
å¹³å‡æ—¶é—´: ~299ms
æ ‡å‡†å·®: ~5ms
```

---

**æŠ¥å‘Šæ—¥æœŸ**: 2026-02-09
**ä¼˜åŒ–é˜¶æ®µ**: é˜¶æ®µ1ä¿®å¤
**çŠ¶æ€**: âœ… å®Œæˆ
**ä¸‹ä¸€æ­¥**: é˜¶æ®µ2 - å‘é‡åŒ–float_encoder

---

## é™„å½•: è¯¦ç»†æ€§èƒ½æ•°æ®

### ä¿®å¤å‰ (ä½¿ç”¨ç¼“å­˜)
```
è¿­ä»£ 1/10: 431.09ms
è¿­ä»£ 2/10: 391.86ms
è¿­ä»£ 3/10: 386.99ms
è¿­ä»£ 4/10: 375.72ms
è¿­ä»£ 5/10: 376.13ms
è¿­ä»£ 6/10: 371.93ms
è¿­ä»£ 7/10: 385.01ms
è¿­ä»£ 8/10: 388.79ms
è¿­ä»£ 9/10: 395.09ms
è¿­ä»£ 10/10: 395.09ms

å¹³å‡: 395.09ms
æ ‡å‡†å·®: 20.51ms
```

### ä¿®å¤å (æ— ç¼“å­˜)
```
è¿­ä»£ 1/10: 292.44ms
è¿­ä»£ 2/10: 304.67ms
è¿­ä»£ 3/10: 299.46ms
è¿­ä»£ 4/10: 309.69ms
è¿­ä»£ 5/10: 295.93ms
è¿­ä»£ 6/10: 292.24ms
è¿­ä»£ 7/10: 296.61ms
è¿­ä»£ 8/10: 299.04ms
è¿­ä»£ 9/10: 300.89ms
è¿­ä»£ 10/10: 300.43ms

å¹³å‡: 299.14ms
æ ‡å‡†å·®: 5.06ms
```

### æ€§èƒ½æ”¹è¿›
```
æ—¶é—´æ”¹è¿›: 395.09ms â†’ 299.14ms (-24%)
ç¨³å®šæ€§æ”¹è¿›: 20.51ms â†’ 5.06ms (-75%)
```
